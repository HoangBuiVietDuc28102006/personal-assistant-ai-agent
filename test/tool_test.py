import json
import requests
from openai import OpenAI
from tools.weather import WeatherTool, WeatherParams  # your tool

client = OpenAI()

# 1. Define tools from your class
tools = [WeatherTool.schema()]

# Function to actually call the weather tool
def get_weather(arguments: str):
    params = WeatherParams(**json.loads(arguments))
    tool = WeatherTool()
    return tool.run(params)

# Create a running input list
input_list = [
    {"role": "user", "content": "What's the weather in Sydney? Coordinates are -33.8688, 151.2093"}
]

# 2. Ask the model, providing the weather tool schema
response = client.responses.create(
    model="gpt-4o-mini",
    tools=tools,
    input=input_list,
)

# Add model output to conversation

# 3. Check if the model decided to call our tool
for item in response.output:
    input_list.append(item.model_dump())

    if item.type == "function_call":
        if item.name == WeatherTool.name:
            # Execute the tool
            weather = get_weather(item.arguments)

            # 4. Provide tool results back to the model
            input_list.append({
                "type": "function_call_output",
                "call_id": item.call_id,
                "output": json.dumps(weather)
            })

print("Final input to model:")
print(json.dumps(input_list, indent=2))

# 5. Ask again, now with tool output available
response = client.responses.create(
    model="gpt-4o-mini",
    instructions="Respond only with the weather report generated by a tool.",
    tools=tools,
    input=input_list,
)

print("Final output:")
print(response.model_dump_json(indent=2))
print("\n" + response.output_text)
